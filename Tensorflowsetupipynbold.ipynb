{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2L-cjBpQl5uB"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7F3ygShHR0k",
    "outputId": "5dd8d629-2e19-49a3-ecab-5cb2133e51e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.8.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cef19\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cef19\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.22.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-9ec4d5268fe5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-9ec4d5268fe5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-m pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ssq9jMw9IgVG",
    "outputId": "a77afcc3-0d1f-4bf3-8e42-2d57f3ca56d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.5.5.64)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyter-client (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.22.2)\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from skimage import io\n",
    "\n",
    "path = glob.glob('C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification\\\\pest_classification\\\\training_dataset\\\\*.jpg')\n",
    "#path = glob.glob('./images/*.jpg')\n",
    "\n",
    "for file in path:\n",
    "    #print(file)\n",
    "    img = io.imread(file)\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('file',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    #print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qsY_AcFqajU4"
   },
   "outputs": [],
   "source": [
    "DATADIR = r\"C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GZescBHWdsv4"
   },
   "outputs": [],
   "source": [
    "directory = r\"C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "7-125ugJdRa7",
    "outputId": "e33c8e9a-45b9-4449-fb77-94e5ae0e7bcd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DATADIR = r\"C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset\"\n",
    "\n",
    "for filename in os.listdir(DATADIR):\n",
    "    if filename.endswith(\".jpeg\"):\n",
    "      #do smth\n",
    "      continue\n",
    "    else:\n",
    "      continue\n",
    "    print(filename)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "aIroSKowZFpF",
    "outputId": "a16c2157-4392-4d40-c6d2-ec3a06e57f92"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CATEGORIES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b4d56d09f77a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#CATEGORIES = [\"Dog\", \"Cat\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mCATEGORIES\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# do dogs and cats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m#path = os.path.join(DATADIR,category)  # create path to dogs and cats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# iterate over each image per dogs and cats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CATEGORIES' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = r\"C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset\"\n",
    "\n",
    "#CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "for dd in CATEGORIES:  # do dogs and cats\n",
    "    #path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    for img in os.listdir():  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "5mJM6G27ZfqR",
    "outputId": "1c4a381b-b93a-4b1d-cc54-9f9b711c7cc9"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 4-5: truncated \\UXXXXXXXX escape (<ipython-input-15-14383bef9259>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-14383bef9259>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    DATADIR = \"r(C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset)\"\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 4-5: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = \"r(C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GTeSNdozeyrE"
   },
   "outputs": [],
   "source": [
    "folder_dir = \"C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification\\\\pest_classification\\\\training_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "ilTef8PXeZji",
    "outputId": "977201b1-d988-45f1-86fa-877ce3f467c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_136.jpeg\n",
      "Image_137.jpeg\n",
      "Image_138.jpeg\n",
      "Image_139.jpeg\n",
      "Image_140.jpeg\n",
      "Image_141.jpeg\n",
      "Image_142.jpeg\n",
      "Image_143.jpeg\n",
      "Image_144.jpeg\n",
      "Image_145.jpeg\n",
      "Image_147.jpeg\n",
      "Image_148.jpeg\n",
      "Image_149.jpeg\n",
      "Image_150.jpeg\n",
      "Image_151.jpeg\n",
      "Image_152.jpeg\n",
      "Image_153.jpeg\n",
      "Image_154.jpeg\n",
      "Image_155.jpeg\n",
      "Image_156.jpeg\n",
      "Image_158.jpeg\n",
      "Image_159.jpeg\n",
      "Image_160.jpeg\n",
      "Image_161.jpeg\n",
      "Image_162.jpeg\n",
      "Image_163.jpeg\n",
      "Image_164.jpeg\n",
      "Image_165.jpeg\n",
      "Image_166.jpeg\n",
      "Image_167.jpeg\n",
      "Image_168.jpeg\n",
      "Image_169.jpeg\n",
      "Image_170.jpeg\n",
      "Image_171.jpeg\n",
      "Image_172.jpeg\n",
      "Image_173.jpeg\n",
      "Image_174.jpeg\n",
      "Image_175.jpeg\n",
      "Image_176.jpeg\n",
      "Image_177.jpeg\n",
      "Image_178.jpeg\n",
      "Image_179.jpeg\n",
      "Image_180.jpeg\n",
      "Image_181.jpeg\n",
      "Image_182.jpeg\n",
      "Image_183.jpeg\n",
      "Image_184.jpeg\n",
      "Image_185.jpeg\n",
      "Image_187.jpeg\n",
      "Image_188.jpeg\n",
      "Image_189.jpeg\n",
      "Image_190.jpeg\n",
      "Image_191.jpeg\n",
      "Image_192.jpeg\n",
      "Image_193.jpeg\n",
      "Image_194.jpeg\n",
      "Image_195.jpeg\n",
      "Image_196.jpeg\n",
      "Image_198.jpeg\n",
      "Image_199.jpeg\n",
      "Image_200.jpeg\n",
      "Image_201.jpeg\n",
      "Image_202.jpeg\n",
      "Image_203.jpeg\n",
      "Image_204.jpeg\n",
      "Image_205.jpeg\n",
      "Image_206.jpeg\n",
      "Image_207.jpeg\n",
      "Image_278.jpeg\n",
      "Image_279.jpeg\n",
      "Image_280.jpeg\n",
      "Image_281.jpeg\n",
      "Image_282.jpeg\n",
      "Image_283.jpeg\n",
      "Image_284.jpeg\n",
      "Image_285.jpeg\n",
      "Image_286.jpeg\n",
      "Image_288.jpeg\n",
      "Image_289.jpeg\n",
      "Image_290.jpeg\n",
      "Image_291.jpeg\n",
      "Image_292.jpeg\n",
      "Image_293.jpeg\n",
      "Image_294.jpeg\n",
      "Image_295.jpeg\n",
      "Image_296.jpeg\n",
      "Image_298.jpeg\n",
      "Image_299.jpeg\n",
      "Image_300.jpeg\n",
      "Image_301.jpeg\n",
      "Image_303.jpeg\n",
      "Image_304.jpeg\n",
      "Image_305.jpeg\n",
      "Image_306.jpeg\n",
      "Image_307.jpeg\n",
      "Image_308.jpeg\n",
      "Image_309.jpeg\n",
      "Image_310.jpeg\n"
     ]
    }
   ],
   "source": [
    "# import the modules\n",
    "import os\n",
    "from os import listdir\n",
    " \n",
    "# get the path/directory\n",
    "#folder_dir = r\"C:\\Users\\cef19\\Desktop\\DPhi\\World_League_Datathon\\pest_classification\\pest_classification\\training_dataset\"\n",
    "for images in os.listdir(folder_dir):\n",
    " \n",
    "    # check if the image ends with jpeg\n",
    "    if (images.endswith(\".jpeg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OmWRrQwBgQzq"
   },
   "outputs": [],
   "source": [
    "# import required module\n",
    "from pathlib import Path\n",
    " \n",
    "# get the path/directory\n",
    "folder_dir = \"C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification\\\\pest_classification\\\\training_dataset\\Image_283.jpeg\"\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "images = Path(folder_dir).glob('*.jpeg')\n",
    "for image in images:\n",
    "    print(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-exq3M6ThRNR"
   },
   "outputs": [],
   "source": [
    "# import required module\n",
    "import glob\n",
    " \n",
    "# get the path/directory\n",
    "folder_dir = \"C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification\\\\pest_classification\\\\training_dataset\\Image_283.jpeg\"\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "for images in glob.iglob(f'{folder_dir}/*'):\n",
    "   \n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".jpeg\")):\n",
    "        print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpT_oI5tisW6",
    "outputId": "343c0cbf-b52d-4c5b-fb33-8288ab147266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification': ['.ipynb_checkpoints', 'Image_1.jpg', 'pest_classification', 'Tensorflowsetupipynb.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification/data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-360c7097c0f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/data/train/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\cef19\\\\Desktop\\\\DPhi\\\\World_League_Datathon\\\\pest_classification/data/train/'"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import numpy as np  \n",
    "from keras.preprocessing import image \n",
    " \n",
    "PATH = os.getcwd() \n",
    " \n",
    "train_path = PATH+'/data/train/' \n",
    "train_batch = os.listdir(train_path) \n",
    "x_train = [] \n",
    " \n",
    "# if data are in form of images \n",
    "for sample in train_data: \n",
    "\timg_path = train_path+sample \n",
    "\tx = image.load_img(img_path) \n",
    "\t# preprocessing if required \n",
    "\tx_train.append(x) \n",
    " \n",
    "test_path = PATH+'/data/test/' \n",
    "test_batch = os.listdir(test_path) \n",
    "x_test = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tensorflowsetupipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
